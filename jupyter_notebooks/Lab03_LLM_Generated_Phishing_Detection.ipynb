{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-badge",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/RiverGumSecurity/AILabs/blob/main/Lab03_LLM_Generated_Phishing/LLM_Generated_Phishing.ipynb\" target=\"_new\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro-markdown",
   "metadata": {},
   "source": [
    "# Lab 03: LLM-Generated Phishing Detection\n",
    "\n",
    "In this lab, we explore the intersection of generative AI and cybersecurity by investigating whether Large Language Models (LLMs) can generate phishing emails that evade detection by machine learning-based classifiers.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand how to interact with LLM APIs (OpenAI and Anthropic)\n",
    "2. Generate synthetic phishing content using prompt engineering\n",
    "3. Evaluate generated content against a pre-trained phishing detection model\n",
    "4. Analyze the implications for cybersecurity defenses\n",
    "\n",
    "## Background\n",
    "\n",
    "In Lab 01, we trained statistical machine learning models to detect phishing emails. In Lab 02, we used a pre-trained BERT model fine-tuned for phishing detection. Now we will explore the **adversarial** side: can an attacker use generative AI to craft phishing emails that bypass these defenses?\n",
    "\n",
    "This lab demonstrates a critical concept in AI security: the **arms race** between offensive and defensive AI capabilities. As defenders build better detection models, attackers may leverage the same AI technologies to generate more convincing attacks.\n",
    "\n",
    "**Ethical Note**: This lab is for educational purposes only. The techniques demonstrated here should only be used in authorized security testing, research, and defensive planning contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": "## Part 1: Environment Setup\n\nThe required packages are pre-installed in this environment. We need:\n- `openai` - OpenAI API client\n- `anthropic` - Anthropic API client  \n- `transformers` - HuggingFace transformers for the BERT model\n- `torch` - PyTorch for model inference"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-packages",
   "metadata": {},
   "outputs": [],
   "source": "# Verify required packages are available\nimport importlib\n\npackages = ['openai', 'anthropic', 'transformers', 'torch', 'huggingface_hub']\nmissing = []\n\nfor pkg in packages:\n    try:\n        importlib.import_module(pkg)\n        print(f'[+] {pkg} is available')\n    except ImportError:\n        missing.append(pkg)\n        print(f'[!] {pkg} is missing')\n\nif missing:\n    print(f'\\n[!] Installing missing packages: {\", \".join(missing)}')\n    import subprocess\n    subprocess.check_call(['pip', 'install', '-q'] + missing)\n    print('[+] Installation complete!')\nelse:\n    print('\\n[+] All required packages are available!')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "## Lab 03: LLM-Generated Phishing Detection\n",
    "## AI for Cybersecurity Professionals\n",
    "#################################################\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import torch\n",
    "import huggingface_hub\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional\n",
    "\n",
    "# LLM API clients\n",
    "import openai\n",
    "import anthropic\n",
    "\n",
    "print(f'Python version: {sys.version}')\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Transformers version: {transformers.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-keys-section",
   "metadata": {},
   "source": [
    "## Part 2: API Key Configuration\n",
    "\n",
    "You will need API keys for the services you want to use:\n",
    "\n",
    "- **OpenAI API Key**: Get one at https://platform.openai.com/api-keys\n",
    "- **Anthropic API Key**: Get one at https://console.anthropic.com/\n",
    "- **HuggingFace API Key**: Get one at https://huggingface.co/settings/tokens\n",
    "\n",
    "You can configure these in several ways:\n",
    "1. Environment variables (`OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `HF_TOKEN`)\n",
    "2. Files in your home directory (`.openai_key`, `.anthropic_key`, `.hfkey`)\n",
    "3. Google Colab secrets (if running in Colab)\n",
    "4. Direct input when prompted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "api-key-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_key(key_name: str, env_var: str, file_name: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Retrieve an API key from various sources.\n",
    "    Priority: Environment variable > File > Colab secrets > None\n",
    "    \"\"\"\n",
    "    # Check environment variable first\n",
    "    key = os.environ.get(env_var)\n",
    "    if key:\n",
    "        print(f'[+] {key_name} loaded from environment variable')\n",
    "        return key\n",
    "    \n",
    "    # Check file in home directory\n",
    "    key_file = pathlib.Path.home() / file_name\n",
    "    if key_file.exists():\n",
    "        with open(key_file) as f:\n",
    "            key = f.read().strip()\n",
    "            if key:\n",
    "                print(f'[+] {key_name} loaded from ~/{file_name}')\n",
    "                return key\n",
    "    \n",
    "    # Check Google Colab secrets\n",
    "    if 'google.colab' in sys.modules:\n",
    "        try:\n",
    "            from google.colab import userdata\n",
    "            key = userdata.get(env_var)\n",
    "            if key:\n",
    "                print(f'[+] {key_name} loaded from Colab secrets')\n",
    "                return key\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    print(f'[-] {key_name} not found')\n",
    "    return None\n",
    "\n",
    "# Load API keys\n",
    "OPENAI_API_KEY = get_api_key('OpenAI API Key', 'OPENAI_API_KEY', '.openai_key')\n",
    "ANTHROPIC_API_KEY = get_api_key('Anthropic API Key', 'ANTHROPIC_API_KEY', '.anthropic_key')\n",
    "HF_API_KEY = get_api_key('HuggingFace API Key', 'HF_TOKEN', '.hfkey')\n",
    "\n",
    "# Determine which LLM provider to use\n",
    "LLM_PROVIDER = None\n",
    "if OPENAI_API_KEY:\n",
    "    LLM_PROVIDER = 'openai'\n",
    "elif ANTHROPIC_API_KEY:\n",
    "    LLM_PROVIDER = 'anthropic'\n",
    "\n",
    "if LLM_PROVIDER:\n",
    "    print(f'\\n[*] Will use {LLM_PROVIDER.upper()} for text generation')\n",
    "else:\n",
    "    print('\\n[!] WARNING: No LLM API key found. Please set OPENAI_API_KEY or ANTHROPIC_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-key-entry",
   "metadata": {},
   "source": [
    "### Manual API Key Entry (Optional)\n",
    "\n",
    "If your API keys were not automatically detected, you can enter them manually below. **Do not commit notebooks with API keys to version control!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-key-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and fill in if needed:\n",
    "\n",
    "# OPENAI_API_KEY = 'sk-...'  # Your OpenAI API key\n",
    "# ANTHROPIC_API_KEY = 'sk-ant-...'  # Your Anthropic API key\n",
    "# HF_API_KEY = 'hf_...'  # Your HuggingFace API key\n",
    "\n",
    "# Update provider selection if you set keys manually\n",
    "if OPENAI_API_KEY and not LLM_PROVIDER:\n",
    "    LLM_PROVIDER = 'openai'\n",
    "    print('[*] Will use OPENAI for text generation')\n",
    "elif ANTHROPIC_API_KEY and not LLM_PROVIDER:\n",
    "    LLM_PROVIDER = 'anthropic'\n",
    "    print('[*] Will use ANTHROPIC for text generation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bert-setup-section",
   "metadata": {},
   "source": "## Part 3: Load the Phishing Detection Model\n\nWe'll use the same BERT-based phishing detection model from Lab 02: `ealvaradob/bert-finetuned-phishing`\n\nThis model is pre-downloaded in the lab environment for faster loading.\n\n**Model Performance:**\n- **Accuracy**: 97.17%\n- **Precision**: 96.58%\n- **Recall**: 96.70%\n- **False Positive Rate**: 2.49%"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-bert-model",
   "metadata": {},
   "outputs": [],
   "source": "# Detect available compute device\ndevice = 'cpu'\nif torch.cuda.is_available():\n    device = 'cuda'\nelif torch.backends.mps.is_available():\n    device = 'mps'\nprint(f'[*] Using device: {device}')\n\n# Load the phishing detection model (pre-downloaded in Docker environment)\nmodel_name = \"ealvaradob/bert-finetuned-phishing\"\nprint(f'[*] Loading model: {model_name}')\n\n# Create tokenizer, model, and prediction pipeline\n# The model is cached locally, so this will be fast\ntokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\nmodel = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)\nphishing_detector = transformers.pipeline(\n    'text-classification', \n    model=model, \n    tokenizer=tokenizer, \n    device=device,\n    truncation=True\n)\n\nprint('[+] Phishing detection model loaded successfully!')"
  },
  {
   "cell_type": "markdown",
   "id": "test-detector",
   "metadata": {},
   "source": [
    "### Test the Phishing Detector\n",
    "\n",
    "Let's verify the model works by testing it with some sample emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test samples\n",
    "test_emails = [\n",
    "    \"Hi John, just wanted to follow up on our meeting yesterday. Let me know if you have any questions about the project timeline.\",\n",
    "    \"URGENT: Your account has been compromised! Click here immediately to verify your identity: http://secure-bank-login.com/verify\",\n",
    "    \"Dear valued customer, we noticed suspicious activity on your PayPal account. Please confirm your details within 24 hours or your account will be suspended.\",\n",
    "    \"Thanks for the great presentation today! I'll send over the slides by end of day.\"\n",
    "]\n",
    "\n",
    "print('Testing phishing detector with sample emails:\\n')\n",
    "print('-' * 80)\n",
    "for i, email in enumerate(test_emails, 1):\n",
    "    result = phishing_detector(email)[0]\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    print(f'Email {i}: {email[:60]}...')\n",
    "    print(f'  -> Classification: {label.upper()} (confidence: {score:.2%})')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm-generation-section",
   "metadata": {},
   "source": "## Part 4: LLM Text Generation Functions\n\nNow we'll create functions to generate text using either OpenAI or Anthropic APIs. These functions will be used to generate synthetic phishing emails.\n\n### Understanding the APIs\n\n- **OpenAI API**: Uses the Chat Completions endpoint with models like `gpt-4.1-mini`\n- **Anthropic API**: Uses the Messages endpoint with models like `claude-sonnet-4-20250514`\n\nBoth APIs follow a similar pattern: you send a system prompt (optional) and user message, and receive a generated response."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llm-functions",
   "metadata": {},
   "outputs": [],
   "source": "def generate_with_openai(prompt: str, system_prompt: str = None, model: str = \"gpt-4.1-mini\") -> str:\n    \"\"\"\n    Generate text using OpenAI's API.\n    \n    Args:\n        prompt: The user prompt/instruction\n        system_prompt: Optional system-level instructions\n        model: The OpenAI model to use\n    \n    Returns:\n        Generated text response\n    \"\"\"\n    client = openai.OpenAI(api_key=OPENAI_API_KEY)\n    \n    messages = []\n    if system_prompt:\n        messages.append({\"role\": \"system\", \"content\": system_prompt})\n    messages.append({\"role\": \"user\", \"content\": prompt})\n    \n    response = client.chat.completions.create(\n        model=model,\n        messages=messages,\n        max_tokens=1024,\n        temperature=0.7\n    )\n    \n    return response.choices[0].message.content\n\n\ndef generate_with_anthropic(prompt: str, system_prompt: str = None, model: str = \"claude-sonnet-4-20250514\") -> str:\n    \"\"\"\n    Generate text using Anthropic's API.\n    \n    Args:\n        prompt: The user prompt/instruction\n        system_prompt: Optional system-level instructions\n        model: The Anthropic model to use\n    \n    Returns:\n        Generated text response\n    \"\"\"\n    client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n    \n    kwargs = {\n        \"model\": model,\n        \"max_tokens\": 1024,\n        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n    }\n    \n    if system_prompt:\n        kwargs[\"system\"] = system_prompt\n    \n    response = client.messages.create(**kwargs)\n    \n    return response.content[0].text\n\n\ndef generate_text(prompt: str, system_prompt: str = None) -> str:\n    \"\"\"\n    Generate text using the configured LLM provider.\n    \"\"\"\n    if LLM_PROVIDER == 'openai':\n        return generate_with_openai(prompt, system_prompt)\n    elif LLM_PROVIDER == 'anthropic':\n        return generate_with_anthropic(prompt, system_prompt)\n    else:\n        raise ValueError(\"No LLM provider configured. Please set an API key.\")\n\nprint(f'[+] LLM generation functions defined (provider: {LLM_PROVIDER})')"
  },
  {
   "cell_type": "markdown",
   "id": "generation-experiment",
   "metadata": {},
   "source": [
    "## Part 5: Generating Phishing Emails with LLMs\n",
    "\n",
    "Now we'll use the LLM to generate synthetic phishing emails. We'll explore different prompting strategies and see how well the generated emails evade the phishing detector.\n",
    "\n",
    "### Ethical Context\n",
    "\n",
    "This exercise simulates what an attacker might do to test and improve their phishing campaigns. Understanding these techniques helps security professionals:\n",
    "1. Build better detection systems\n",
    "2. Create more realistic training data\n",
    "3. Develop security awareness training materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate-phishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompts for generating phishing emails\n",
    "# These prompts are designed for security research and awareness training\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a cybersecurity researcher creating phishing email examples \n",
    "for security awareness training purposes. Generate realistic but clearly educational \n",
    "examples that demonstrate common phishing tactics.\"\"\"\n",
    "\n",
    "phishing_prompts = [\n",
    "    # Basic urgency-based phishing\n",
    "    \"\"\"For a security awareness training module, write an example phishing email \n",
    "    that pretends to be from a bank warning about suspicious account activity. \n",
    "    Include typical phishing elements like urgency and a call to action.\"\"\",\n",
    "    \n",
    "    # Tech support scam\n",
    "    \"\"\"Create an example phishing email for training purposes that impersonates \n",
    "    IT support, claiming the recipient's password is expiring and they need to \n",
    "    update it immediately.\"\"\",\n",
    "    \n",
    "    # Package delivery scam\n",
    "    \"\"\"Write a sample phishing email for security training that pretends to be \n",
    "    from a delivery company about a package that couldn't be delivered.\"\"\",\n",
    "    \n",
    "    # Invoice/payment scam\n",
    "    \"\"\"Generate an example business email compromise (BEC) phishing email for \n",
    "    awareness training that appears to be an invoice requiring urgent payment.\"\"\",\n",
    "    \n",
    "    # Social media account security\n",
    "    \"\"\"Create a sample phishing email for training that impersonates a social \n",
    "    media platform warning about a security issue with the account.\"\"\"\n",
    "]\n",
    "\n",
    "print(f'Defined {len(phishing_prompts)} phishing generation prompts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate phishing emails and test against the detector\n",
    "if LLM_PROVIDER:\n",
    "    results = []\n",
    "    \n",
    "    print('Generating and analyzing phishing emails...\\n')\n",
    "    print('=' * 80)\n",
    "    \n",
    "    for i, prompt in enumerate(phishing_prompts, 1):\n",
    "        print(f'\\n[Generating Email {i}/{len(phishing_prompts)}]')\n",
    "        \n",
    "        try:\n",
    "            # Generate the phishing email\n",
    "            generated_email = generate_text(prompt, SYSTEM_PROMPT)\n",
    "            \n",
    "            # Classify with the phishing detector\n",
    "            detection_result = phishing_detector(generated_email)[0]\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'prompt_id': i,\n",
    "                'generated_email': generated_email,\n",
    "                'detection_label': detection_result['label'],\n",
    "                'detection_score': detection_result['score']\n",
    "            })\n",
    "            \n",
    "            # Display results\n",
    "            print(f'\\nGenerated Email:')\n",
    "            print('-' * 40)\n",
    "            print(generated_email[:500] + ('...' if len(generated_email) > 500 else ''))\n",
    "            print('-' * 40)\n",
    "            print(f'Detection Result: {detection_result[\"label\"].upper()} '\n",
    "                  f'(confidence: {detection_result[\"score\"]:.2%})')\n",
    "            \n",
    "            # Check if phishing was detected\n",
    "            if detection_result['label'] == 'phishing':\n",
    "                print('>> DETECTED as phishing')\n",
    "            else:\n",
    "                print('>> EVADED detection (classified as benign)')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Error generating email: {e}')\n",
    "            results.append({\n",
    "                'prompt_id': i,\n",
    "                'generated_email': f'ERROR: {e}',\n",
    "                'detection_label': 'error',\n",
    "                'detection_score': 0\n",
    "            })\n",
    "    \n",
    "    print('\\n' + '=' * 80)\n",
    "    print('Generation complete!')\n",
    "else:\n",
    "    print('No LLM provider configured. Please set an API key to generate emails.')\n",
    "    results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-section",
   "metadata": {},
   "source": [
    "## Part 6: Analysis and Visualization\n",
    "\n",
    "Let's analyze the results to understand how well the BERT model detects LLM-generated phishing emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-dataframe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results:\n",
    "    # Create a DataFrame for analysis\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Filter out errors\n",
    "    df_valid = df[df['detection_label'] != 'error']\n",
    "    \n",
    "    print('Summary of Generated Phishing Email Detection:\\n')\n",
    "    print(df_valid[['prompt_id', 'detection_label', 'detection_score']].to_string(index=False))\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total = len(df_valid)\n",
    "    detected = len(df_valid[df_valid['detection_label'] == 'phishing'])\n",
    "    evaded = total - detected\n",
    "    \n",
    "    print(f'\\n--- Statistics ---')\n",
    "    print(f'Total emails generated: {total}')\n",
    "    print(f'Detected as phishing: {detected} ({detected/total:.1%})')\n",
    "    print(f'Evaded detection: {evaded} ({evaded/total:.1%})')\n",
    "else:\n",
    "    print('No results to analyze. Please run the generation cell first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results and len(df_valid) > 0:\n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Pie chart of detection results\n",
    "    detection_counts = df_valid['detection_label'].value_counts()\n",
    "    colors = ['red' if label == 'phishing' else 'green' for label in detection_counts.index]\n",
    "    axes[0].pie(detection_counts, labels=detection_counts.index, autopct='%1.1f%%', \n",
    "                colors=colors, startangle=90)\n",
    "    axes[0].set_title('Detection Results for LLM-Generated Phishing Emails')\n",
    "    \n",
    "    # Bar chart of confidence scores\n",
    "    colors_bar = ['red' if label == 'phishing' else 'green' for label in df_valid['detection_label']]\n",
    "    axes[1].bar(df_valid['prompt_id'], df_valid['detection_score'], color=colors_bar)\n",
    "    axes[1].set_xlabel('Email #')\n",
    "    axes[1].set_ylabel('Detection Confidence')\n",
    "    axes[1].set_title('Detection Confidence by Email')\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].axhline(y=0.5, color='gray', linestyle='--', label='50% threshold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No results to visualize.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evasion-experiment",
   "metadata": {},
   "source": [
    "## Part 7: Evasion Techniques (Advanced)\n",
    "\n",
    "Let's explore whether we can craft prompts that generate emails more likely to evade detection. This helps us understand the limitations of ML-based detection.\n",
    "\n",
    "**Note**: Understanding evasion techniques is crucial for building robust defenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evasion-prompts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More sophisticated prompts that might evade detection\n",
    "evasion_prompts = [\n",
    "    # Conversational/personal tone\n",
    "    \"\"\"For security research, write a phishing email that uses a friendly, \n",
    "    conversational tone like it's from a colleague. It should subtly request \n",
    "    the recipient to click a link to review a shared document.\"\"\",\n",
    "    \n",
    "    # Minimal urgency, professional\n",
    "    \"\"\"Create a very professional, formal business email for training purposes \n",
    "    that requests verification of account details. Avoid urgent language and \n",
    "    make it sound like routine business communication.\"\"\",\n",
    "    \n",
    "    # Context-aware/personalized\n",
    "    \"\"\"Write a phishing email example that appears to be a follow-up to a \n",
    "    previous conversation about a project. Include natural language and \n",
    "    references to work topics.\"\"\"\n",
    "]\n",
    "\n",
    "print(f'Defined {len(evasion_prompts)} evasion-style prompts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-evasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evasion prompts\n",
    "if LLM_PROVIDER:\n",
    "    evasion_results = []\n",
    "    \n",
    "    print('Testing evasion-style phishing emails...\\n')\n",
    "    print('=' * 80)\n",
    "    \n",
    "    for i, prompt in enumerate(evasion_prompts, 1):\n",
    "        print(f'\\n[Evasion Email {i}/{len(evasion_prompts)}]')\n",
    "        \n",
    "        try:\n",
    "            generated_email = generate_text(prompt, SYSTEM_PROMPT)\n",
    "            detection_result = phishing_detector(generated_email)[0]\n",
    "            \n",
    "            evasion_results.append({\n",
    "                'prompt_id': i,\n",
    "                'generated_email': generated_email,\n",
    "                'detection_label': detection_result['label'],\n",
    "                'detection_score': detection_result['score']\n",
    "            })\n",
    "            \n",
    "            print(f'\\nGenerated Email:')\n",
    "            print('-' * 40)\n",
    "            print(generated_email[:500] + ('...' if len(generated_email) > 500 else ''))\n",
    "            print('-' * 40)\n",
    "            print(f'Detection: {detection_result[\"label\"].upper()} ({detection_result[\"score\"]:.2%})')\n",
    "            \n",
    "            if detection_result['label'] == 'benign':\n",
    "                print('>> SUCCESS: Evaded detection!')\n",
    "            else:\n",
    "                print('>> Detected as phishing')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f'Error: {e}')\n",
    "    \n",
    "    # Summary\n",
    "    if evasion_results:\n",
    "        evaded = sum(1 for r in evasion_results if r['detection_label'] == 'benign')\n",
    "        print(f'\\n--- Evasion Results ---')\n",
    "        print(f'Evaded detection: {evaded}/{len(evasion_results)}')\n",
    "else:\n",
    "    print('No LLM provider configured.')\n",
    "    evasion_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "custom-testing",
   "metadata": {},
   "source": [
    "## Part 8: Interactive Testing\n",
    "\n",
    "Use this section to test your own prompts and emails against the detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your own prompt\n",
    "custom_prompt = \"\"\"\n",
    "For security awareness training, write a phishing email that appears to be \n",
    "from HR about updating direct deposit information for payroll.\n",
    "\"\"\"\n",
    "\n",
    "if LLM_PROVIDER:\n",
    "    print('Generating email from custom prompt...\\n')\n",
    "    custom_email = generate_text(custom_prompt, SYSTEM_PROMPT)\n",
    "    \n",
    "    print('Generated Email:')\n",
    "    print('-' * 60)\n",
    "    print(custom_email)\n",
    "    print('-' * 60)\n",
    "    \n",
    "    result = phishing_detector(custom_email)[0]\n",
    "    print(f'\\nDetection: {result[\"label\"].upper()} (confidence: {result[\"score\"]:.2%})')\n",
    "else:\n",
    "    print('No LLM provider configured.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-custom-email",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test any email text directly against the detector\n",
    "test_email = \"\"\"\n",
    "Hi team,\n",
    "\n",
    "I hope this email finds you well. I wanted to share a quick update on the \n",
    "Q4 project timeline. Please review the attached document and let me know \n",
    "if you have any questions.\n",
    "\n",
    "Click here to access the shared folder: [link]\n",
    "\n",
    "Best regards,\n",
    "John\n",
    "\"\"\"\n",
    "\n",
    "result = phishing_detector(test_email)[0]\n",
    "print(f'Test email classification: {result[\"label\"].upper()}')\n",
    "print(f'Confidence: {result[\"score\"]:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions",
   "metadata": {},
   "source": [
    "## Part 9: Conclusions and Discussion\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "From this lab, we observed:\n",
    "\n",
    "1. **LLMs can generate convincing phishing content**: Modern language models can produce realistic phishing emails that mimic various attack styles.\n",
    "\n",
    "2. **Detection effectiveness varies**: The BERT-based detector catches many generated phishing emails, but some may evade detection depending on the writing style and approach.\n",
    "\n",
    "3. **Style matters for evasion**: Emails with more conversational, professional tones may be harder to detect than obvious urgent/threatening messages.\n",
    "\n",
    "### Implications for Cybersecurity\n",
    "\n",
    "**Offensive Perspective:**\n",
    "- Attackers can use LLMs to generate large volumes of varied phishing content\n",
    "- Personalized, context-aware phishing becomes easier to create at scale\n",
    "- Traditional signature-based detection may struggle with novel generated content\n",
    "\n",
    "**Defensive Perspective:**\n",
    "- ML-based detection needs to be trained on diverse, evolving threats\n",
    "- LLM-generated phishing should be included in training datasets\n",
    "- Multi-layered detection (content + metadata + behavioral) is essential\n",
    "- User education remains critical as the last line of defense\n",
    "\n",
    "### Discussion Questions\n",
    "\n",
    "1. How might organizations improve their phishing detection to handle LLM-generated content?\n",
    "\n",
    "2. What ethical considerations should guide the use of AI in both offensive and defensive cybersecurity?\n",
    "\n",
    "3. How does this lab change your perspective on security awareness training?\n",
    "\n",
    "4. What additional signals (beyond text content) could help detect AI-generated phishing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenge-exercise",
   "metadata": {},
   "source": [
    "## Challenge Exercise\n",
    "\n",
    "Try the following exercises to deepen your understanding:\n",
    "\n",
    "1. **Prompt Engineering Challenge**: Create a prompt that generates a phishing email that evades the detector. What characteristics make it successful?\n",
    "\n",
    "2. **Defense Analysis**: Test the same generated emails against the statistical models from Lab 01 (Logistic Regression, SVM, etc.). Do they perform differently?\n",
    "\n",
    "3. **Volume Testing**: Generate 50+ phishing emails with varied prompts and calculate the overall evasion rate.\n",
    "\n",
    "4. **Comparative Analysis**: Compare outputs from OpenAI vs Anthropic models - do they produce different detection results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenge-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for challenge exercises\n",
    "# Your code here...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}